# Lipneting

Lipneting is a deep learning-based lipâ€‘reading model that translates silent video clips of lip movements into text. This repository contains the endâ€‘toâ€‘end implementation, from data preprocessing and model training to inference and evaluation.

---

## ğŸ“ Project Structure

```txt
Lipneting/
â”œâ”€â”€ data/                   # Raw and processed video data
â”‚   â”œâ”€â”€ raw/                # Original video files (not tracked)
â”‚   â””â”€â”€ processed/          # Frame-extracted and preprocessed images
â”‚
â”œâ”€â”€ models/                 # Model definitions
â”‚   â”œâ”€â”€ lipnet.py           # LipNet architecture definition
â”‚   â””â”€â”€ utils.py            # Helper functions (data loaders, augmentations)
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks for EDA and experiments
â”‚   â””â”€â”€ training_experiments.ipynb
â”‚
â”œâ”€â”€ checkpoints/            # Saved model weights
â”‚
â”œâ”€â”€ outputs/                # Training logs and evaluation results
â”‚
â”œâ”€â”€ README.md               # Project overview and instructions
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ .gitignore
```

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/Lipneting.git
cd Lipneting
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Prepare the data

* Place raw video files in `data/raw/`.
* Run preprocessing to extract frames:

  ```bash
  python models/utils.py --mode preprocess --input data/raw/ --output data/processed/
  ```

### 4. Train the model

```bash
python models/lipnet.py --train --data_dir data/processed/ --epochs 50 --batch_size 16
```

### 5. Evaluate and Inference

```bash
python models/lipnet.py --evaluate --weights checkpoints/best_model.h5
python models/lipnet.py --infer --video samples/lip_clip.mp4
```

---

## ğŸ“„ Requirements

See `requirements.txt` for exact versions:

```
TensorFlow>=2.4.0
opencv-python
numpy
pandas
matplotlib
scikit-learn
```

---

## ğŸ“¡ Dataset

This project uses the GRID corpus for lip-reading experiments. Download instructions:

1. Go to [GRID Corpus](https://spandh.dcs.shef.ac.uk/gridcorpus/) and request access.
2. Unzip into `data/raw/GRID/`.

---

## ğŸ¤ Contributing

Feel free to open issues or submit pull requests for improvements.

---

## ğŸ“œ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.
